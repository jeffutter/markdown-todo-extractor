{"id":"markdown-todo-extractor-tx9","title":"Create Additional Tools","description":"# Create Additional Tools\n\nThis epic encompasses the creation of additional LLM tools to enhance the knowledge base interaction capabilities. The tools extend the existing RAG search functionality to provide more granular access to vault contents.\n\n## Overview\n\nThis epic adds four complementary tools that give the LLM more ways to explore and access the Obsidian vault:\n\n| Tool | Purpose | Child Ticket |\n|------|---------|--------------|\n| **read_file** | Read the full content of a specific file | tx9.2 |\n| **list_files** | Browse the directory structure | tx9.3 |\n| **list_tags** | Discover available tags with statistics | tx9.4 |\n| **search_by_tags** | Find files matching specific tags | tx9.5 |\n\n## Implementation Plan\n\n### Architecture Approach\n\nAll four tools will follow the existing patterns established in `src/mcp.rs`:\n\n1. **MCP Tool Registration**: Use the `#[tool]` macro from `rmcp` to register each tool with the `TaskSearchService`\n2. **REST API Endpoints**: Add corresponding HTTP handlers in `main.rs` for the HTTP MCP server mode\n3. **Shared Extractors**: Reuse and extend existing extractors (`TaskExtractor`, `TagExtractor`) where applicable\n4. **Configuration Integration**: All tools should respect the existing `Config` path exclusion patterns\n\n### File Organization\n\nNew functionality will be added to existing modules following the current structure:\n\n- `src/mcp.rs` - Add new tool methods and request/response types\n- `src/main.rs` - Add new HTTP endpoint handlers\n- `src/tag_extractor.rs` - Extend with tag counting and file-by-tag lookup capabilities\n\nNo new modules are required; extend existing ones to maintain cohesion.\n\n### Common Patterns\n\nAll tools should:\n1. Accept paths relative to the base path (vault root)\n2. Return JSON responses with consistent error handling via `ErrorData`\n3. Support both MCP stdio and HTTP modes\n4. Include comprehensive tool descriptions for LLM consumption\n5. Use `JsonSchema` derive for automatic schema generation\n\n### Execution Order\n\nThe tools can be implemented in any order, but the suggested sequence optimizes reuse:\n\n1. **tx9.2 - read_file**: Standalone, no dependencies\n2. **tx9.3 - list_files**: Standalone, no dependencies\n3. **tx9.4 - list_tags**: Requires extending TagExtractor with counting\n4. **tx9.5 - search_by_tags**: Can reuse tag extraction logic from tx9.4\n\n### Testing Strategy\n\nEach tool should include:\n1. Unit tests for core logic\n2. Integration tests for MCP tool invocation\n3. Manual testing with the CLI and MCP stdio modes","status":"open","priority":2,"issue_type":"epic","owner":"jeff@jeffutter.com","created_at":"2026-01-19T18:43:26.983361979-06:00","created_by":"Jeffery Utter","updated_at":"2026-01-19T18:59:30.315196643-06:00"}
{"id":"markdown-todo-extractor-tx9.2","title":"Create File Read Tool","description":"# Create File Read Tool\n\nCreate a tool that returns the contents of a file at a given path.\n\n## Requirements\n\n- The tool should return the contents of the file at a given path\n- See this for ideas: https://github.com/logancyang/obsidian-copilot/blob/master/src/tools/NoteTools.ts\n\n## Implementation Plan\n\n### 1. Add Request/Response Types in `src/mcp.rs`\n\nAdd new structures for the read_file tool:\n\n```rust\n/// Parameters for the read_file tool\n#[derive(Debug, Deserialize, JsonSchema)]\npub struct ReadFileRequest {\n    #[schemars(description = \"Path to the file relative to the vault root (e.g., 'Projects/plan.md')\")]\n    pub path: String,\n}\n\n/// Response for the read_file tool\n#[derive(Debug, Serialize, Deserialize, JsonSchema)]\npub struct ReadFileResponse {\n    pub path: String,\n    pub file_name: String,\n    pub content: String,\n    pub size_bytes: usize,\n}\n```\n\n### 2. Implement MCP Tool Method in `TaskSearchService`\n\nAdd the `read_file` tool method to the `#[tool_router] impl TaskSearchService` block:\n\n```rust\n#[tool(description = \"Read the full content of a markdown file from the vault. Provide the path relative to the vault root.\")]\nasync fn read_file(\n    \u0026self,\n    Parameters(request): Parameters\u003cReadFileRequest\u003e,\n) -\u003e Result\u003cJson\u003cReadFileResponse\u003e, ErrorData\u003e {\n    // Resolve the full path\n    let full_path = self.base_path.join(\u0026request.path);\n    \n    // Validate the path is within base_path (security check)\n    // Validate the file exists and is a .md file\n    // Read and return the content\n}\n```\n\n### 3. Security Considerations\n\n- **Path Traversal Prevention**: Ensure the resolved path stays within the vault by canonicalizing both paths and checking that the file path starts with the base path\n- **File Type Validation**: Optionally restrict to `.md` files only, or allow all text files\n- **Size Limits**: Consider adding a maximum file size to prevent memory issues (configurable via env var similar to `MARKDOWN_TODO_EXTRACTOR_DEFAULT_LIMIT`)\n\n### 4. Add HTTP Endpoint in `main.rs`\n\nAdd REST API handlers for the new tool:\n\n```rust\n/// HTTP handler for reading files (GET with query params)\nasync fn read_file_handler_get(\n    axum::extract::State(state): axum::extract::State\u003cAppState\u003e,\n    query: axum::extract::Query\u003cmcp::ReadFileRequest\u003e,\n) -\u003e Result\u003caxum::Json\u003cmcp::ReadFileResponse\u003e, (axum::http::StatusCode, String)\u003e {\n    read_file_impl(state, query.0).await\n}\n\n/// HTTP handler for reading files (POST with JSON body)\nasync fn read_file_handler_post(\n    axum::extract::State(state): axum::extract::State\u003cAppState\u003e,\n    axum::Json(request): axum::Json\u003cmcp::ReadFileRequest\u003e,\n) -\u003e Result\u003caxum::Json\u003cmcp::ReadFileResponse\u003e, (axum::http::StatusCode, String)\u003e {\n    read_file_impl(state, request).await\n}\n```\n\nAdd route registration:\n```rust\n.route(\n    \"/api/file\",\n    axum::routing::get(read_file_handler_get).post(read_file_handler_post),\n)\n```\n\n### 5. Update Tools Handler\n\nAdd the new tool to the `/tools` endpoint schema:\n\n```rust\nlet read_file_schema = schema_for!(ReadFileRequest);\n// Add to tools array:\n{\n    \"name\": \"read_file\",\n    \"description\": \"Read the full content of a markdown file from the vault\",\n    \"input_schema\": read_file_schema\n}\n```\n\n### 6. Error Handling\n\nReturn appropriate error codes:\n- `404 Not Found` - File does not exist\n- `403 Forbidden` - Path traversal attempt detected\n- `400 Bad Request` - Invalid path format\n- `500 Internal Server Error` - File read error\n\n### 7. Testing\n\nAdd tests in `src/mcp.rs`:\n- Test successful file read\n- Test path traversal prevention (`../` attempts)\n- Test non-existent file handling\n- Test file outside vault handling\n\n### Files to Modify\n\n1. `/home/jeffutter/src/markdown-todo-extractor/src/mcp.rs` - Add tool and types\n2. `/home/jeffutter/src/markdown-todo-extractor/src/main.rs` - Add HTTP handlers and routes","status":"open","priority":2,"issue_type":"feature","owner":"jeff@jeffutter.com","created_at":"2026-01-19T18:49:51.850252653-06:00","created_by":"Jeffery Utter","updated_at":"2026-01-19T19:00:34.514618417-06:00","dependencies":[{"issue_id":"markdown-todo-extractor-tx9.2","depends_on_id":"markdown-todo-extractor-tx9","type":"parent-child","created_at":"2026-01-19T18:49:51.855943654-06:00","created_by":"Jeffery Utter"}]}
{"id":"markdown-todo-extractor-tx9.3","title":"Create file list tool","description":"# Create file list tool\n\nCreate a tool to list the directory tree of the obsidian vault.\n\n- The tree should include all files and folders.\n- Reference this for ideas: https://github.com/logancyang/obsidian-copilot/blob/master/src/tools/FileTreeTools.ts\n\nThis tool will provide the LLM with a complete view of the vault's file structure, enabling it to:\n- Understand the organization of notes and folders\n- Navigate to specific files or folders\n- Discover what documents exist in a particular area\n\n---\n\n## Implementation Plan\n\n### Overview\n\nThis plan creates a new `list_files` MCP tool that returns a hierarchical file tree representation of the Obsidian vault. The design follows the existing patterns in the codebase (like `extract_tags` and `search_tasks`) while drawing inspiration from the obsidian-copilot FileTreeTools implementation.\n\n### Output Format\n\nThe tool will return a JSON structure representing the file tree:\n\n```json\n{\n  \"tree\": {\n    \"name\": \"vault\",\n    \"path\": \"/\",\n    \"type\": \"directory\",\n    \"children\": [\n      {\n        \"name\": \"Notes\",\n        \"path\": \"/Notes\",\n        \"type\": \"directory\",\n        \"children\": [\n          {\n            \"name\": \"daily-note.md\",\n            \"path\": \"/Notes/daily-note.md\",\n            \"type\": \"file\"\n          }\n        ],\n        \"file_count\": 1\n      },\n      {\n        \"name\": \"README.md\",\n        \"path\": \"/README.md\",\n        \"type\": \"file\"\n      }\n    ],\n    \"file_count\": 2\n  },\n  \"total_files\": 2,\n  \"total_directories\": 1\n}\n```\n\n### Parameters\n\nThe tool should accept these optional parameters:\n\n| Parameter | Type | Description |\n|-----------|------|-------------|\n| `subpath` | `Option\u003cString\u003e` | Subpath within the vault to list (defaults to root) |\n| `max_depth` | `Option\u003cusize\u003e` | Maximum depth to traverse (defaults to unlimited) |\n| `include_hidden` | `Option\u003cbool\u003e` | Include hidden files/folders (defaults to false) |\n| `markdown_only` | `Option\u003cbool\u003e` | Only include .md files (defaults to false) |\n\n---\n\n### Step-by-Step Implementation\n\n#### Step 1: Create the File Tree Module\n\nCreate a new file `/home/jeffutter/src/markdown-todo-extractor/src/file_tree.rs` with:\n\n1. **Data Structures**:\n   ```rust\n   #[derive(Debug, Clone, Serialize, Deserialize, JsonSchema)]\n   pub struct FileTreeNode {\n       pub name: String,\n       pub path: String,  // Relative path from vault root\n       #[serde(rename = \"type\")]\n       pub node_type: NodeType,\n       #[serde(skip_serializing_if = \"Option::is_none\")]\n       pub children: Option\u003cVec\u003cFileTreeNode\u003e\u003e,\n       #[serde(skip_serializing_if = \"Option::is_none\")]\n       pub file_count: Option\u003cusize\u003e,  // For directories: count of files in subtree\n   }\n\n   #[derive(Debug, Clone, Serialize, Deserialize, JsonSchema)]\n   #[serde(rename_all = \"lowercase\")]\n   pub enum NodeType {\n       File,\n       Directory,\n   }\n   ```\n\n2. **FileTreeBuilder struct**:\n   - Store configuration (Config) for path exclusion support\n   - Store building options (max_depth, include_hidden, markdown_only)\n\n3. **Core methods**:\n   - `pub fn new(config: Arc\u003cConfig\u003e) -\u003e Self`\n   - `pub fn build_tree(\u0026self, root: \u0026Path, options: \u0026BuildOptions) -\u003e Result\u003cFileTreeNode, ...\u003e`\n   - `fn build_tree_recursive(\u0026self, path: \u0026Path, relative_path: \u0026str, current_depth: usize, options: \u0026BuildOptions) -\u003e Result\u003cOption\u003cFileTreeNode\u003e, ...\u003e`\n\n4. **Key implementation details**:\n   - Reuse `Config::should_exclude()` for path exclusion (same patterns as task extraction)\n   - Sort children alphabetically (directories first, then files)\n   - Use `rayon` for parallel directory traversal (match existing patterns)\n   - Track file counts recursively for each directory node\n\n#### Step 2: Add to MCP Service\n\nUpdate `/home/jeffutter/src/markdown-todo-extractor/src/mcp.rs`:\n\n1. **Add imports and response structs**:\n   ```rust\n   use crate::file_tree::{FileTreeBuilder, FileTreeNode};\n\n   #[derive(Debug, Serialize, Deserialize, JsonSchema)]\n   pub struct ListFilesResponse {\n       pub tree: FileTreeNode,\n       pub total_files: usize,\n       pub total_directories: usize,\n   }\n\n   #[derive(Debug, Deserialize, JsonSchema)]\n   pub struct ListFilesRequest {\n       #[schemars(description = \"Subpath within the vault to list (optional)\")]\n       pub subpath: Option\u003cString\u003e,\n       \n       #[schemars(description = \"Maximum depth to traverse (optional, defaults to unlimited)\")]\n       pub max_depth: Option\u003cusize\u003e,\n       \n       #[schemars(description = \"Include hidden files and folders (optional, defaults to false)\")]\n       pub include_hidden: Option\u003cbool\u003e,\n       \n       #[schemars(description = \"Only include markdown (.md) files (optional, defaults to false)\")]\n       pub markdown_only: Option\u003cbool\u003e,\n   }\n   ```\n\n2. **Add FileTreeBuilder to TaskSearchService**:\n   ```rust\n   pub struct TaskSearchService {\n       // ... existing fields ...\n       file_tree_builder: Arc\u003cFileTreeBuilder\u003e,\n   }\n   ```\n\n3. **Add the tool method**:\n   ```rust\n   #[tool(description = \"List the file and folder structure of the vault\")]\n   async fn list_files(\n       \u0026self,\n       Parameters(request): Parameters\u003cListFilesRequest\u003e,\n   ) -\u003e Result\u003cJson\u003cListFilesResponse\u003e, ErrorData\u003e {\n       // Implementation\n   }\n   ```\n\n#### Step 3: Add HTTP REST Endpoint\n\nUpdate `/home/jeffutter/src/markdown-todo-extractor/src/main.rs`:\n\n1. Add HTTP handlers for GET/POST `/api/files`:\n   ```rust\n   async fn files_handler_get(...) -\u003e Result\u003c...\u003e { ... }\n   async fn files_handler_post(...) -\u003e Result\u003c...\u003e { ... }\n   async fn list_files_impl(...) -\u003e Result\u003c...\u003e { ... }\n   ```\n\n2. Register the route:\n   ```rust\n   .route(\n       \"/api/files\",\n       axum::routing::get(files_handler_get).post(files_handler_post),\n   )\n   ```\n\n3. Update `tools_handler()` to include the new tool schema.\n\n#### Step 4: Add CLI Support\n\nUpdate `/home/jeffutter/src/markdown-todo-extractor/src/cli.rs`:\n\n1. Add a new subcommand variant:\n   ```rust\n   #[derive(Subcommand, Debug)]\n   pub enum Commands {\n       // ... existing ...\n       /// List files and folders in the vault\n       Files(Box\u003cFilesCommand\u003e),\n   }\n\n   #[derive(Parser, Debug)]\n   pub struct FilesCommand {\n       #[arg(required = true)]\n       pub path: PathBuf,\n       \n       #[arg(long)]\n       pub max_depth: Option\u003cusize\u003e,\n       \n       #[arg(long)]\n       pub include_hidden: bool,\n       \n       #[arg(long)]\n       pub markdown_only: bool,\n   }\n   ```\n\n2. Handle the command in `run_cli()`.\n\n#### Step 5: Update Module Declarations\n\nUpdate `/home/jeffutter/src/markdown-todo-extractor/src/main.rs`:\n- Add `mod file_tree;` declaration\n\n#### Step 6: Update Server Instructions\n\nIn `/home/jeffutter/src/markdown-todo-extractor/src/mcp.rs`, update the `instructions` field in `get_info()` to mention the new `list_files` tool.\n\n---\n\n### Size Management (Optional Enhancement)\n\nLike the obsidian-copilot implementation, consider adding size management:\n\n- If the JSON response exceeds a threshold (e.g., 100KB), return a simplified version:\n  - Only directory structure (no files)\n  - Or only top N levels\n  - Include a `truncated: true` flag and `truncation_reason` in the response\n\nThis can be implemented by:\n1. First building the full tree\n2. Serializing to check size\n3. If too large, rebuild with reduced options\n4. Add `truncated` and `truncation_reason` fields to `ListFilesResponse`\n\n---\n\n### Testing Strategy\n\n1. **Unit tests in `file_tree.rs`**:\n   - Test empty directory handling\n   - Test hidden file filtering\n   - Test markdown-only filtering\n   - Test max_depth limiting\n   - Test path exclusion via Config\n   - Test file counting\n\n2. **Integration test**:\n   - Create a test directory structure\n   - Verify JSON output matches expected structure\n\n---\n\n### Files to Create/Modify\n\n| File | Action | Description |\n|------|--------|-------------|\n| `src/file_tree.rs` | **CREATE** | New module for file tree building |\n| `src/mcp.rs` | MODIFY | Add `list_files` tool and response types |\n| `src/main.rs` | MODIFY | Add `mod file_tree`, HTTP endpoints |\n| `src/cli.rs` | MODIFY | Add `files` subcommand |\n| `CLAUDE.md` | MODIFY | Document the new tool |\n\n---\n\n### Dependencies\n\nNo new crate dependencies required. The implementation uses:\n- `serde` / `serde_json` (already present)\n- `schemars` (already present)\n- `rayon` (already present for parallelism)\n- `std::fs` (standard library)\n\n---\n\n### Acceptance Criteria\n\n1. MCP tool `list_files` is available and documented\n2. HTTP REST endpoint `/api/files` works with GET and POST\n3. CLI subcommand `files` outputs JSON file tree\n4. Path exclusions from `.markdown-todo-extractor.toml` are respected\n5. Optional parameters (subpath, max_depth, include_hidden, markdown_only) work correctly\n6. Output includes file counts for directories\n7. Server instructions updated to describe the tool","status":"open","priority":2,"issue_type":"feature","owner":"jeff@jeffutter.com","created_at":"2026-01-19T18:50:16.158158253-06:00","created_by":"Jeffery Utter","updated_at":"2026-01-19T19:00:39.636867411-06:00","dependencies":[{"issue_id":"markdown-todo-extractor-tx9.3","depends_on_id":"markdown-todo-extractor-tx9","type":"parent-child","created_at":"2026-01-19T18:50:16.15909786-06:00","created_by":"Jeffery Utter"}]}
{"id":"markdown-todo-extractor-tx9.4","title":"Tag List Tool","description":"# Tag List Tool\n\nCreate a tool to list all tags with their document counts.\n\n## Requirements\n\n- In the list, include the tag name and number of documents that reference it.\n- Tags should be pulled from the vault\n- Tags are in the YAML frontmatter of the files in the `tags` key\n- Reference this for ideas: https://github.com/logancyang/obsidian-copilot/blob/master/src/tools/TagTools.ts\n\nThis tool will provide the LLM with a complete inventory of all tags in the vault, along with statistics on how many documents reference each tag. This enables:\n- Understanding the tag taxonomy used in the vault\n- Finding commonly used vs. rarely used tags\n- Discovering topics with the most content\n- Supporting tag-based search and filtering decisions\n\n","status":"open","priority":2,"issue_type":"feature","owner":"jeff@jeffutter.com","created_at":"2026-01-19T18:50:38.764378029-06:00","created_by":"Jeffery Utter","updated_at":"2026-01-19T18:52:09.706490213-06:00","dependencies":[{"issue_id":"markdown-todo-extractor-tx9.4","depends_on_id":"markdown-todo-extractor-tx9","type":"parent-child","created_at":"2026-01-19T18:50:38.764956166-06:00","created_by":"Jeffery Utter"}]}
{"id":"markdown-todo-extractor-tx9.5","title":"Tag Search Tool","description":"# Tag Search Tool\n\nCreate a tool to list files based on tags.\n\n## Requirements\n\n- Tags should be searched for in the vault.\n- Tags are in the YAML frontmatter of files under the 'tags' key\n\n\nThis tool enables the LLM to find documents that match specific tags from their YAML frontmatter. Unlike the semantic search in RAG, this provides exact tag-based filtering, useful for:\n- Finding all documents with a particular tag\n- Finding documents that match multiple tags (AND/OR logic)\n- Browsing content by topic/category\n","status":"open","priority":2,"issue_type":"feature","owner":"jeff@jeffutter.com","created_at":"2026-01-19T18:51:01.199607478-06:00","created_by":"Jeffery Utter","updated_at":"2026-01-19T18:52:26.707380558-06:00","dependencies":[{"issue_id":"markdown-todo-extractor-tx9.5","depends_on_id":"markdown-todo-extractor-tx9","type":"parent-child","created_at":"2026-01-19T18:51:01.200457025-06:00","created_by":"Jeffery Utter"}]}
